---
title: "munge d08a"
output: html_document
---

```{r}
library(plyr)
library(tidyverse)
library(jsonlite)
library(lubridate)
library(stringr)
library(digest)
```

```{r}
#results.dir = "sandbox-results/"
results.dir = "production-results/"
```

```{r}
parsed.json = Map(fromJSON, paste0(results.dir, list.files(results.dir, pattern = "*.json")))
# strip results dir from names in parsed.json
names(parsed.json) = gsub(names(parsed.json),pattern = results.dir, replacement = "")

# also strip ".json"
names(parsed.json) = gsub(names(parsed.json),pattern = ".json", replacement = "")
```

```{r}
from.turk.time <- function(x) {
  parse_date_time(x, "%Y-%m-%d%H:%M%:%S%z")
}
```


```{r}
all.assignments = do.call(
  rbind,
  Map(unname(parsed.json),
      f = function(x) {
        
        # extract ip, if we have it
        ip = NA
        
        if (is.list(x$answers$fingerprint)) {
          if (is.list(x$answers$fingerprint$geo)) {
            ip = x$answers$fingerprint$geo$ip
          }
        }
        
        d = with(x,
                 data.frame(id = AssignmentId,
                            worker.id = substring(sha1(paste0(WorkerId, "dummy")), 0, 7),
                            accept.time = from.turk.time(AcceptTime),
                            submit.time = from.turk.time(SubmitTime),
                            ip = ip
                 ))
        
        d.questionnaire = as.data.frame(x$answers$questionnaire$outputs) %>%
          rename(regex.experience = regex,
                 programming.experience = programming)
        
        cbind(d, d.questionnaire)
      }
  ))
```

# exclude data

```{r}
exclude = list()
```

## exclude duplicate IPs

```{r}
exclude$duplicate.ip <- filter(all.assignments, !is.na(ip), duplicated(ip))$id
```

## apply exclusions

```{r}
excluded.assignment.ids = unlist(exclude$duplicate.ip)
assignments = all.assignments %>% filter(!(id %in% excluded.assignment.ids))
```

# write out assignments

```{r}
write.csv(assignments, file = paste0(results.dir, "assignments.csv"), row.names = FALSE)
```

# write out responses for assignments

```{r}
raw.responses = parsed.json[assignments$id]
```


```{r}
rule.ids = c('3a','zip-code','suffix-s')
```

```{r}
shorten.responses = function(d) {
  d %>%
    group_by(teacher.id, rule.id) %>% 
    mutate(num.examples = length(string),
           string.and.pol = paste0('"', string, '" ', c(positive = '+', negative = '-')[polarity])) %>%
    group_by(teacher.id, rule.id) %>%
    summarise(exs = paste0(string.and.pol, collapse = ' â€– ')) %>%
    select(exs, teacher.id, rule.id)
}

glosses = do.call(
  rbind,
  Map(unname(raw.responses),
      f = function(x) {
        
        d = with(x,
                 data.frame(assignment.id = AssignmentId,
                            worker.id = substring(sha1(paste0(WorkerId, "dummy")), 0, 7)))
        
        d.exs = do.call(rbind, Map(shorten.responses, x$answers$receive$examples)) %>%
          rename(seq.id = teacher.id)
        
        # join examples for each rule with the metadata about the rule (id, desc, trial num)
        d.responses = with(x$answers$receive,
                           data.frame(rule.id = id, gloss.id = glossId, gloss = gloss, gloss.correct = correct, seq.id = seqId))
        
        d %>% merge(d.exs) %>% merge(d.responses)
        
      }))
```



```{r}
write.csv(glosses, file = paste0(results.dir, "gloss.csv"), row.names = FALSE)
```


