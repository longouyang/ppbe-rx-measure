---
title: "analyze"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries}
library(MASS)
library(plyr)
library(tidyverse)
library(lubridate)
library(memoise)
```

TODO: upgrade to R 3.3.2 so that ggplot warning goes away


```{r utilities}
generic.ci_ <- function(x, n = 5000, seed = 1) {
  set.seed(seed)
  lenx = length(x)
  
  structure(
    quantile(
      replicate(n, mean(x[sample.int(lenx, replace = TRUE)])),
      c(0.025, 0.975)),
    names=c("ci.l","ci.u"))
}

generic.ci <- memoise(generic.ci_)
```

# read in data

```{r}
results.dir = "production-results/"
assignments = read_csv(paste0(results.dir, "assignments.csv")) %>%
  mutate(accept.time = ymd_hms(accept.time),
         submit.time = ymd_hms(submit.time),
         duration = difftime(submit.time, accept.time, units = "mins"))
responses = read_csv(paste0(results.dir, "responses.csv"),
                     col_types = cols(string = col_character()))

## arrange assignments in order of time
assignments = assignments %>% arrange(accept.time)
```


```{r compute-example-correctness}
regexes = c('3a' = 'aaa+',
            'zip-code' = '[0123456789]{5}',
            'consonants-only' = '[bcdfghjklmnpqrstvwxyzBCDFGHJKLMNPQRSTVWXYZ]*',
            'delimiters' = "\\[.*\\]")

example.matches = function(example, rx) {
  res = regexpr(pattern = rx, text = example)
  # make sure we match and that the *entire* string is what matches, not a substring
  res > 0 & attr(res, "match.length") == nchar(example)
}
# example.correct(example = 'aaa', rx = 'aaa+')
# example.correct(example = 'baaa', rx = 'aaa+')
# example.correct(example = 'aaaa', rx = 'aaa+')

responses = responses %>%
  mutate(rx = regexes[rule.id])

responses_match = apply(responses[,c('string','rx')],
      1,
      function(e) { example.matches(example = e['string'], rx = e['rx']) })

responses = mutate(responses,
                   match = responses_match,
                   correct = !xor(polarity == 'positive', match)) %>%
  select(-rx, -rule.desc) # hide these cause they're verbose

# # testing
# View(responses %>% select(rule.id, polarity, string, correct, match) %>% arrange(rule.id, polarity))
```


# auxiliary

## how long does the task take?

```{r}
qplot(data = assignments,
      x = as.numeric(duration),
      binwidth = 1,
      color = I('white')) + 
  xlab("duration (minutes)")
```


## what did people think was a fair payment?

```{r}
fair.pay = assignments$fair_pay %>% as.numeric %>% na.omit
fair.pay = fair.pay[fair.pay < 5]
qplot(x = fair.pay,
      binwidth = 0.1,
      color = I('white')
      )
```

## how old are people?

```{r}
qplot(data = assignments,
      x = age,
      binwidth = 5)
```

they all tend to be older

## what gender are they?

```{r}
table(tolower(substr(assignments$gender, start = 1, stop = 1)))
```

## what is their programming / regex experience?

```{r}
assignments %>% select(worker.id, age, gender, programming.experience, regex.experience) %>% arrange(desc(nchar(programming.experience)))
```
there's maybe 10 people with some sort of experience.

### do the people with regex experience give interesting examples?

```{r}
regex.knowers = c("7af1a7e", "85357a3", "f0cc52f", "6b3b421", "e91432b", "295bd50")
responses %>% filter(worker.id %in% regex.knowers) %>% select(worker.id, rule.id, example.num, polarity, string)
```

- 7af1a7e, delimiters: nested them in `[[valid]]`, also used semantics in `[anythingcouldgohere]`
- 85357a3, delimiters: listed a bunch of negative examples and then transformed them into positive ones
- 295bd50, delimiters: listed a bunch of negative examples and then transformed them into positive ones
- 295bd50, consonants-only: listed individual vowels as negative examples
- 85357a3, 3a: listed all lengths from 1 to 8 a's

note that there is more interesting behavior here compared to d02. that could be because i changed the instructions to emphasize helpfulness. or it could be because i got more people with programming / regex experience in this sample (and had a larger sample).

## any bugs?

```{r}
assignments %>% select(bugs, worker.id) %>% arrange(desc(nchar(bugs)))
```

not quite sure i understand the feedback from 6487c8d. they appear to have done everything correctly except for the delimiters example.

## how much did they enjoy the task?

```{r}
assignments %>% select(enjoy) %>% arrange(desc(nchar(enjoy)))
```


# research

## how many examples do people give?

```{r, fig.width = 11, fig.height = 3}
e.agg = responses %>% group_by(worker.id, rule.id) %>%
  summarise(num.examples = n()) %>%
  group_by(rule.id, num.examples) %>%
  summarise(freq = n())

xmin = 1 #min(e.agg$num.examples)
xmax = max(e.agg$num.examples)

e.agg$num.examples.fct = factor(e.agg$num.examples, levels = as.character(xmin:xmax))

ggplot(data = e.agg) +
  facet_grid(. ~ rule.id) +
  geom_bar(mapping = aes(x = num.examples.fct, y = freq), stat = 'identity') +
  scale_x_discrete(breaks = as.character(xmin:xmax), drop = FALSE, name = 'number of examples')
```

now 2 examples is no longer the mode.

## q: do 2-examples tend to be *balanced*? i.e., one positive and one negative?

```{r}
e.agg = responses %>%
  group_by(worker.id, rule.id) %>%
  mutate(num.examples = length(string)) %>%
  filter(num.examples == 2) %>%
  group_by(worker.id, rule.id) %>%
  summarise(num.pos = sum(polarity == 'positive'),
            num.neg = sum(polarity == 'negative'))

print(table(e.agg$num.pos, e.agg$num.neg))

# proportion test on the frequency of balanced 2-examples
prop.test(x = sum(e.agg$num.pos == 1), nrow(e.agg))
```

overwhelmingly, yes (nb: would need to collect more data for the proportion test, which i believe operates better if the minimum cell count is 5)

### for balanced 2-examples, what is the mean edit distance?

```{r}
e.agg = responses %>%
  group_by(worker.id, rule.id) %>%
  mutate(num.examples = length(string)) %>%
  filter(num.examples == 2, sum(polarity == 'positive') == 1) %>%
  summarise(edit.distance = adist(string)[1,2])

mean.balanced.pair.edit.distance = mean(e.agg$edit.distance)

qplot(data = e.agg,
      x = edit.distance,
      color = I('white'),
      binwidth = 1) + scale_x_continuous(breaks = with(e.agg, min(edit.distance):max(edit.distance))) +
  geom_vline(xintercept = mean.balanced.pair.edit.distance, color = I('red'))
```

are these examples are closer than you'd expect by chance? (permutation test)

```{r}
e.agg = responses %>%
  group_by(worker.id, rule.id) %>%
  mutate(num.examples = length(string)) %>%
  filter(num.examples == 2, sum(polarity == 'positive') == 1)

workers.and.rules = e.agg[,c('worker.id', 'rule.id')]

balanced.example.pair.edit.distance.bootstrap = function(pool) {
  # sample a permuted dataset:
  # for each rule, shuffle all the examples and then pair them off
  # then for each pair, compute edit distance
  
  syn.df = ddply(pool,
        .(rule.id), function(e) {
          pool.pos = e[e$polarity == 'positive',]$string
          pool.neg = e[e$polarity == 'negative',]$string
          
          syn.pos = sample(pool.pos)
          syn.neg = sample(pool.neg)
          
          syn = rbind(syn.pos, syn.neg)
          
          data.frame(distance = apply(X = syn, MARGIN = 2, F = function(pair) { adist(pair)[1,2] }))
        })
  
  mean(syn.df$dist)
}

time = system.time(bootstrap.samples <- replicate(5000, balanced.example.pair.edit.distance.bootstrap(e.agg)))

writeLines(paste0("elapsed seconds: ", round(unname(time['elapsed']), 1)))

writeLines(paste0('95% ci for bootstrap: ', paste0(quantile(bootstrap.samples, c(0.025, 0.0975)), collapse = " - ")))

# one-tailed test: how many bootstrap samples have a mean
# number of clusters less than the observed sample?
sum(bootstrap.samples < mean.balanced.pair.edit.distance) / length(bootstrap.samples)
```


#### the second most likely edit distance for balanced 2-examples is 5: is there a pattern there? or is that just the zip code rule?

```{r}
responses %>%
  group_by(worker.id, rule.id) %>%
  mutate(num.examples = length(string)) %>%
  filter(num.examples == 2, sum(polarity == 'positive') == 1) %>%
  summarise(edit.distance = adist(string)[1,2]) %>%
  filter(edit.distance == 5) %>%
  select(-edit.distance) %>%
  merge(responses)
```

in d02, it was mostly zip code. but here it's not.

## how many positive examples versus negative examples?

```{r, fig.width = 11, fig.height = 3}
e.agg = responses %>% group_by(worker.id, rule.id) %>%
  summarise(num.pos = sum(polarity == "positive"),
            num.neg = sum(polarity == "negative")) %>%
  ungroup() %>%
  group_by(num.pos, num.neg, rule.id) %>%
  summarise(freq = n())

qplot(data = e.agg,
      facets = . ~ rule.id,
      x = num.pos,
      y = num.neg,
      size = freq) +
  geom_abline() + 
  scale_x_continuous(name = '# positive examples', breaks = c(0, 3, 6), limits = c(0, 7)) +
  scale_y_continuous(name = '# negative examples', breaks = c(0, 3, 6), limits = c(0, 7))
```

things are somewhat balanced -- people tend to give some negative examples.

### q: do people give more positive examples than negative?

simple check -- paired t-test between number of positive and number of negative examples for each trial X user.

```{r}
e.agg = responses %>% group_by(worker.id, rule.id) %>%
  summarise(num.pos = sum(polarity == "positive"),
            num.neg = sum(polarity == "negative"))

with(e.agg, t.test(num.pos, num.neg, paired = TRUE))
```

there is a small preference to give positive examples:
on average, people give 0.45 more positive examples than negative. people give 4.325 examples on average.
and there is plenty of variation:

```{r}
e = data.frame(diff = e.agg$num.pos - e.agg$num.neg) %>% group_by(diff) %>% summarise(freq = n())
ggplot(data = e) +
  geom_bar(mapping = aes(x = diff, y = freq), stat = 'identity')
```


## how related are the examples in edit distance?

```{r}
cluster.examples = function(strings, distance.threshold = 2) {
  distance.matrix = adist(strings)
  
  # for each string, figure out which other strings it's similar to
  # (i.e., has edit distance less than the threshold)
  similarities = apply(distance.matrix,
        1,# by row
        function(row) {
          which(row <= distance.threshold)
        })
  clusters = list()
  # print(similarities)
  
  # make the clusters
  Map(1:length(strings),
      f = function(i) {
        # j is the index of the previously created cluster that can contain this string
        j = Position(x = clusters,
                     f = function(cluster) { i %in% cluster })
        
        if (is.na(j)) {
          clusters[[length(clusters) + 1]] <<- similarities[[i]]
        } else {
          clusters[[j]] <<- union(clusters[[j]], similarities[[i]])
        }
      })
  
  # return a list of clusters (each cluster is a vector containing strings that are clustered together)
  Map(clusters, f = function(indices) { strings[indices] })

  # ### WIP ###
  # # return a data frame with two columns: string and cluster number
  # x = do.call(rbind,
  #         Map(clusters,
  #             1:length(clusters),
  #             f = function(indices, cluster.label) {
  #               data.frame(string = strings[indices],
  #                          cluster.label = cluster.label)
  #             }
  #         ))
  # 
  # if (nrow(x) > length(strings)) {
  #   browser()
  # }
  # 
  # x
}

# # testing
strings = c("01234", "012a4", "62804", "628041", "y6280", "0123", "280", "a280b")
# #strings = c('aaa','aa','aaab','baaaab','bbaaabb')
# ## strings = c("94301", "40510", "33333", "r2349", "asdfa", "3621", "834920")
cluster.examples(strings)
```

mean number of clusters for an example sequence:

```{r}
responses.clustered = responses %>%
  group_by(worker.id, rule.id) %>%
  mutate(cluster.label = cluster.examples(string)$cluster.label)

responses.clustered %>%
  group_by(worker.id, rule.id) %>%
  summarise(num.clusters = max(cluster.label)) %>%
  group_by(worker.id) %>%
  summarise(mean_num.clusters = mean(num.clusters)) %>%
  select(mean_num.clusters) %>%
  summary
```

TODO: do there tend to be more negative examples within a cluster? (i think people might come up with one example and then demonstrate various ways it can be perturbed to be a non-example)

TODO: do examples within a cluster tend to be nearby in the sequence of examples the user gave?

comparison to permutation test: sample random participants by sampling from pool of all participants' responses (note that this is sampling *without* replacement, as people wouldn't give the same example twice)
- runtime note: takes around 770 seconds for 5k bootstrap samples. it's a little slow because my clustering function is not vectorized

```{r}
sample.bootstrap.subject = function(worker.id, rule.id) {
  # get examples given by all participants for this rule
  ## written in non-dplyr syntax because i think it might be faster?
  pool = responses[responses$rule.id == rule.id,]
  pool.pos = pool[pool$polarity == 'positive',]$string
  pool.neg = pool[pool$polarity == 'negative',]$string
  
  # get this worker's examples
  this = pool[pool$worker.id == worker.id,]
  
  num.pos = sum(this$polarity == 'positive')
  num.neg = sum(this$polarity == 'negative')
  
  syn.pos = sample(x = pool.pos, size = num.pos, replace = FALSE)
  syn.neg = sample(x = pool.neg, size = num.neg, replace = FALSE)
  
  c(num.clusters = max(cluster.examples(c(syn.pos, syn.neg))$cluster.label))
}

workers.and.rules = responses.clustered[,c('worker.id', 'rule.id')]

clusters.bootstrap = function() {
  num.clusters = apply(workers.and.rules,
                       1,
                       function(e) { 
                         sample.bootstrap.subject(e['worker.id'], e['rule.id'])
                       })
  
  mean(num.clusters)
}

time = system.time(bootstrap.samples <- replicate(500, clusters.bootstrap()))

writeLines(paste0("elapsed seconds: ", round(unname(time['elapsed']), 1)))

writeLines(paste0('95% ci for bootstrap: ', paste0(quantile(bootstrap.samples, c(0.025, 0.0975)), collapse = " - ")))

# one-tailed test: how many bootstrap samples have a mean
# number of clusters less than the observed sample?
sum(bootstrap.samples < mean.num.clusters) / length(bootstrap.samples)
```

TODO: the ways i've done both permutation tests are, i think, reasonable, but there are also reasonable alternatives. talk through my choices with mike, then write down rationale.

## how many mistakes do people make? (e.g., positive examples that don't actually match or negative examples that do match)


by stimulus:

```{r}
responses %>%
  group_by(rule.id) %>%
  summarise(error.rate = sum(!correct) / n())
```

inspecting errors:

```{r}
responses %>% filter(!correct) %>% select(rule.id, worker.id, string, polarity, match, correct) %>% arrange(rule.id)
```

issues
- 3a: people largely interpreted this to be partial matching, not full. also, the issues with lower versus uppercase a's persists.
- zip-code: people largely interpreted this to be partial matching, not full. 


by person:
```{r}
e = responses %>%
  group_by(worker.id) %>%
  summarise(error.rate = sum(!correct) / n()) %>% 
  arrange(desc(error.rate))

qplot(data = e,
      x = error.rate,
      geom = 'histogram')
```

there's quite a heavy tail of people that make errors. one person seemed to have given entirely wrong examples though...

what did that person do?

```{r}
e %>% filter(error.rate == 1) %>% merge(responses) %>%
  select(rule.id, example.num, polarity, string)
```

ah, a lazy worker.

## how long are the examples that people give?

by stimulus:

```{r, fig.width = 11, fig.height = 3}
qplot(data = responses,
      facets = . ~ rule.id,
      x = nchar(string),
      binwidth = 1,
      color = I('white'))
```

by person:

```{r}
qplot(data = responses,
      x = worker.id,
      y = nchar(string), alpha = I(0.5)) + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

## do people give examples in particular orders? e.g., shorter ones first or positive ones first?

### length

un-zscored:
```{r}
e = responses %>%
  transform(len = nchar(string)) %>%
  group_by(example.num) %>%
  summarise(mean.len = mean(len),
            cl.len = generic.ci(len)['ci.l'],
            cu.len = generic.ci(len)['ci.u']) %>%
  ungroup

qplot(data = e,
      x = example.num,
      y = mean.len,
      ymin = cl.len,
      ymax = cu.len,
      geom = c('pointrange','line'))
```

note: confidence intervals for last two points are actually huge (very few unique data values, e.g., 1)

un-z-scored, broken down by rule:

```{r}
e = responses %>%
  transform(len = nchar(string)) %>%
  group_by(example.num, rule.id) %>%
  summarise(mean.len = mean(len),
            cl.len = generic.ci(len)['ci.l'],
            cu.len = generic.ci(len)['ci.u']) %>%
  ungroup

qplot(data = e,
      facets = . ~ rule.id,
      x = example.num,
      y = mean.len,
      ymin = cl.len,
      ymax = cu.len,
      geom = c('pointrange','line'))
```


z-scoring length per subject per rule:
```{r}
z.score <- function(xs) {
  centered = xs - mean(xs)
  if (length(xs) == 1) {
    centered
  } else {
    # NB: deliberately doesn't catch the case where all xs are the same
    # because i filter for this later on
    centered / sd(xs)
  }
}

e = responses %>%
  transform(len = nchar(string)) %>%
  group_by(worker.id, rule.id) %>%
  mutate(z.len = z.score(len)) %>%
  mutate(z.len = ifelse(is.nan(z.len), 0, z.len)) %>%
  group_by(example.num) %>%
  summarise(mean.z.len = mean(z.len),
            cl.len = generic.ci(z.len)['ci.l'],
            cu.len = generic.ci(z.len)['ci.u']) %>%
  ungroup

qplot(data = e,
      x = example.num,
      y = mean.z.len,
      ymin = cl.len,
      ymax = cu.len,
      geom = c('pointrange','line'))
```

doesn't appear to be any sequencing over all the participants, though there are certainly cases where this happens:

```{r}
responses %>% filter(worker.id == 'f0cc52f', rule.id == 'zip-code') %>% select(example.num, polarity, string)
```

in first 4 examples, we have two minimal pairs.

break out previous plot by rule.id:

```{r, fig.width = 11, fig.height = 3}
z.score <- function(xs) {
  centered = xs - mean(xs)
  if (length(xs) == 1) {
    centered
  } else {
    # NB: deliberately doesn't catch the case where all xs are the same
    # because i filter for this later on
    centered / sd(xs)
  }
}

e = responses %>%
  transform(len = nchar(string)) %>%
  group_by(worker.id, rule.id) %>%
  mutate(z.len = z.score(len)) %>%
  mutate(z.len = ifelse(is.nan(z.len), 0, z.len)) %>%
  group_by(example.num, rule.id) %>%
  summarise(mean.z.len = mean(z.len),
            cl.len = generic.ci(z.len)['ci.l'],
            cu.len = generic.ci(z.len)['ci.u']) %>%
  ungroup

qplot(data = e,
      facets = . ~ rule.id,
      x = example.num,
      y = mean.z.len,
      ymin = cl.len,
      ymax = cu.len,
      geom = c('pointrange','line'))
```


for each rule, plot each person's length curve individually:

```{r, fig.width = 8, fig.height = 4, dev="svg"}
e = responses %>%
  transform(len = nchar(string)) %>%
  group_by(worker.id, rule.id) %>%
  mutate(z.len = z.score(len), num.examples = max(example.num)) %>%
  mutate(z.len = ifelse(is.nan(z.len), 0, z.len)) %>%
  filter(num.examples > 1)

qplot(data = e,
      facets = rule.id ~ num.examples,
      x = example.num,
      y = z.len,
      geom = 'line',
      group = worker.id) +
  geom_point(mapping = aes(color = polarity)) +
  scale_color_brewer(palette = "Set1")
```

very busy graph. just looking at polarity:
```{r}
e = responses %>%
  transform(len = nchar(string)) %>%
  group_by(worker.id, rule.id) %>%
  mutate(z.len = z.score(len), num.examples = max(example.num)) %>%
  mutate(z.len = ifelse(is.nan(z.len), 0, z.len))

e = ddply(e, .(rule.id), function(ee) {
  # add dummy indices that are used to layout example sequences vertically
  ee = ee %>%
    arrange(num.examples) %>%
    transform(sort.order = 1:nrow(ee)) # merging will change the order so keep a way of restoring it
  dummy.df = data.frame(worker.id = unique(ee$worker.id))
  dummy.df$dummy.id = 1:nrow(dummy.df)
  merge(ee, dummy.df) %>% arrange(sort.order)
})

qplot(data = e,
      facets = . ~ rule.id,
      x = example.num,
      y = dummy.id,
      fill = polarity,
      color = I('white'),
      geom = 'tile') +
  scale_fill_brewer(palette = "Set1")
```




- 2-examples are balanced
- we see few entirely positive sequences
- possible pattern: all positive followed by all negative


### polarity

```{r}
e = responses %>%
        group_by(example.num) %>%
        summarise(frac.pos = sum(polarity == 'positive') / n(),
                  ci.l = generic.ci(polarity == 'positive')['ci.l'],
                  ci.u = generic.ci(polarity == 'positive')['ci.u'])

qplot(data = e,
      x = example.num,
      y = frac.pos,
      ymin = ci.l,
      ymax = ci.u,
      geom = c('pointrange','line'))
```

interesting -- first example tends to be positive.
also interesting: subsequent examples are roughly a coin flip between positive and negative. so maybe this is where the significant 0.45 more positive examples than negative comes from -- just the first one?

#### within a cluster, does the first example tend to be positive?

```{r}
e = responses.clustered %>%
  group_by(worker.id, rule.id, cluster.label) %>%
  summarise(first.cluster.example.polarity = polarity[1]) %>%
  ungroup() %>%
  select(first.cluster.example.polarity) %>%
  table

print(e)

prop.test(x = e['positive'], n = sum(e))
```

no. looks like it's just the very first example that tends to be positive

## misc

did 90210 show up as a zip code much?
```{r}
responses %>% filter(rule.id == 'zip-code', string == '90210')
```



## looking at raw examples

## 3a

## consonants-only

11 people gave "aeiou":
```{r}
filter(responses, rule.id == 'consonants-only') %>% filter(string == 'aeiou') %>% nrow
```

i wonder -- if i changed the rule to exclude some arbitrary collection of five characters, would people submit /that/ concatenation as a negative example?


## delimiters

### no one nested the brackets (either positively or negatively)

```{r}
responses %>% filter(rule.id == 'delimiters')
```


## zip-code

### negative examples tend to be purely numeric (though there are a few exceptions)

```{r}
e = responses %>%
  filter(rule.id == 'zip-code', polarity == 'negative') %>%
  {example.matches(.$string, "[0123456789]+")}

print(table(e))

prop.test(x = sum(e == TRUE), n = length(e))
```

in d02, i framed this rule in terms of actual zip codes and the negative examples that people gave were, for the most part, entirely numeric.
here, they tend to give more examples that are not entirely numeric.

# comparing afternoon versus morning workers

age difference?

```{r}                      
t.test(assignments[1:20,]$age, assignments[21:40,]$age)
```

not really

gender difference?

```{r}
tbl.gender.time = rbind(table(substr(tolower(assignments[1:20,]$gender), 1, 1)),
          table(substr(tolower(assignments[21:40,]$gender), 1, 1)))

print(tbl.gender.time)

chisq.test(tbl.gender.time)
```

not a significant one

TODO: run the actually interesting analyses on afternoon people versus morning

