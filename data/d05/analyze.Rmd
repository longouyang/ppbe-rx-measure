---
title: "analyze"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries}
library(MASS)
library(plyr)
library(tidyverse)
library(lubridate)
library(memoise)
```

```{r utilities}
generic.ci_ <- function(x, n = 5000, seed = 1) {
  set.seed(seed)
  lenx = length(x)
  
  structure(
    quantile(
      replicate(n, mean(x[sample.int(lenx, replace = TRUE)])),
      c(0.025, 0.975)),
    names=c("ci.l","ci.u"))
}

generic.ci <- memoise(generic.ci_)
```

# read in data

```{r}
results.dir = "production-results/"
assignments = read_csv(paste0(results.dir, "assignments.csv")) %>%
  mutate(accept.time = ymd_hms(accept.time),
         submit.time = ymd_hms(submit.time),
         duration = difftime(submit.time, accept.time, units = "mins"))
responses = read_csv(paste0(results.dir, "responses.csv"),
                     col_types = cols(string = col_character()))

## arrange assignments in order of time
assignments = assignments %>% arrange(accept.time)
```


```{r compute-example-correctness}
regexes = c('3a' = 'aaa+',
            'zip-code' = '[0123456789]{5}',
            'suffix-s' = '.*s\\>',
            'delimiters' = "\\[.*\\]")

example.matches = function(example, rx) {
  res = regexpr(pattern = rx, text = example)
  # make sure we match and that the *entire* string is what matches, not a substring
  res > 0 & attr(res, "match.length") == nchar(example)
}
# example.correct(example = 'aaa', rx = 'aaa+')
# example.correct(example = 'baaa', rx = 'aaa+')
# example.correct(example = 'aaaa', rx = 'aaa+')

responses = responses %>%
  mutate(rx = regexes[rule.id])

responses_match = apply(responses[,c('string','rx')],
      1,
      function(e) { example.matches(example = e['string'], rx = e['rx']) })

responses = responses %>%
  mutate(match = responses_match,
         correct = !xor(polarity == 'positive', match)) %>%
  select(-rx, -rule.desc) # hide these cause they're verbose

# # testing
# View(responses %>% select(rule.id, polarity, string, correct, match) %>% arrange(rule.id, polarity))
```


# auxiliary

## how long does the task take?

```{r}
qplot(data = assignments,
      x = as.numeric(duration),
      binwidth = 1,
      color = I('white')) + 
  xlab("duration (minutes)")
```


## what did people think was a fair payment?

```{r}
fair.pay = gsub("\\$","",assignments$fair_pay) %>% 
  as.numeric %>% na.omit
fair.pay = fair.pay[fair.pay < 6]
qplot(x = fair.pay,
      binwidth = 0.1,
      color = I('white')
      )
```

## how old are people?

```{r}
qplot(data = assignments,
      x = age,
      binwidth = 5)
```

they all tend to be older

## what gender are they?

```{r}
table(tolower(substr(assignments$gender, start = 1, stop = 1)))
```

## what is their programming / regex experience?

```{r}
assignments %>% select(worker.id, programming.experience) %>% arrange(desc(nchar(programming.experience)))
```
there's maybe 16 people with some sort of programming experience.

```{r}
assignments %>% select(worker.id, regex.experience) %>% arrange(desc(nchar(regex.experience)))
```

### do the people with regex experience give interesting examples?

```{r}
regex.knowers = c("ebda6ed", "d2f7661", "c8cecf0", "a33a11b", "9eabb06", "1dc006e", "ec8b199", "e12e476")
responses %>% filter(worker.id %in% regex.knowers) %>% select(worker.id, rule.id, example.num, polarity, string)
```



TODO: analyze

## any bugs?

```{r}
assignments %>% select(bugs, worker.id) %>% arrange(desc(nchar(bugs)))
```

largely smooth

## how much did they enjoy the task?

```{r}
assignments %>% select(enjoy) %>% arrange(desc(nchar(enjoy)))
```

It was decent

# research

## how many examples do people give?

```{r, fig.width = 11, fig.height = 3}
e.agg = responses %>% group_by(worker.id, rule.id) %>%
  summarise(num.examples = n()) %>%
  group_by(rule.id, num.examples) %>%
  summarise(freq = n())

xmin = 1 #min(e.agg$num.examples)
xmax = max(e.agg$num.examples)

e.agg$num.examples.fct = factor(e.agg$num.examples, levels = as.character(xmin:xmax))

ggplot(data = e.agg) +
  facet_grid(. ~ rule.id) +
  geom_bar(mapping = aes(x = num.examples.fct, y = freq), stat = 'identity') +
  scale_x_discrete(breaks = as.character(xmin:xmax), drop = FALSE, name = 'number of examples')
```

## q: do 2-examples tend to be *balanced*? i.e., one positive and one negative?

```{r}
e.agg = responses %>%
  group_by(worker.id, rule.id) %>%
  mutate(num.examples = length(string)) %>%
  filter(num.examples == 2) %>%
  group_by(worker.id, rule.id) %>%
  summarise(num.pos = sum(polarity == 'positive'),
            num.neg = sum(polarity == 'negative'))

print(table(e.agg$num.pos, e.agg$num.neg))

# proportion test on the frequency of balanced 2-examples
prop.test(x = sum(e.agg$num.pos == 1), nrow(e.agg))
```

yes, though not significantly (though i don't have a whole lot of data)

### for balanced 2-examples, what is the mean edit distance?

```{r}
e.agg = responses %>%
  group_by(worker.id, rule.id) %>%
  mutate(num.examples = length(string)) %>%
  filter(num.examples == 2, sum(polarity == 'positive') == 1) %>%
  summarise(edit.distance = adist(string)[1,2])

mean.balanced.pair.edit.distance = mean(e.agg$edit.distance)

qplot(data = e.agg,
      x = edit.distance,
      color = I('white'),
      binwidth = 1) + scale_x_continuous(breaks = with(e.agg, min(edit.distance):max(edit.distance))) +
  geom_vline(xintercept = mean.balanced.pair.edit.distance, color = I('red'))
```

mean is red line -- 4.41.

are these examples are closer than you'd expect by chance? (permutation test)

```{r}
e.agg = responses %>%
  group_by(worker.id, rule.id) %>%
  mutate(num.examples = length(string)) %>%
  filter(num.examples == 2, sum(polarity == 'positive') == 1)

workers.and.rules = e.agg[,c('worker.id', 'rule.id')]

balanced.example.pair.edit.distance.bootstrap = function(pool) {
  # sample a permuted dataset:
  # for each rule, shuffle all the examples and then pair them off
  # then for each pair, compute edit distance
  
  syn.df = ddply(pool,
        .(rule.id), function(e) {
          pool.pos = e[e$polarity == 'positive',]$string
          pool.neg = e[e$polarity == 'negative',]$string
          
          syn.pos = sample(pool.pos)
          syn.neg = sample(pool.neg)
          
          syn = rbind(syn.pos, syn.neg)
          
          data.frame(distance = apply(X = syn, MARGIN = 2, F = function(pair) { adist(pair)[1,2] }))
        })
  
  mean(syn.df$dist)
}

time = system.time(bootstrap.samples <- replicate(5000, balanced.example.pair.edit.distance.bootstrap(e.agg)))

writeLines(paste0("elapsed seconds: ", round(unname(time['elapsed']), 1)))

writeLines(paste0('95% ci for bootstrap: ', paste0(quantile(bootstrap.samples, c(0.025, 0.0975)), collapse = " - ")))

# one-tailed test: how many bootstrap samples have a mean
# number of clusters less than the observed sample?
sum(bootstrap.samples < mean.balanced.pair.edit.distance) / length(bootstrap.samples)
```

yes, this fewer than you'd expect by chance.

## how many positive examples versus negative examples?

```{r, fig.width = 11, fig.height = 3}
e.agg = responses %>% group_by(worker.id, rule.id) %>%
  summarise(num.pos = sum(polarity == "positive"),
            num.neg = sum(polarity == "negative")) %>%
  ungroup() %>%
  group_by(num.pos, num.neg, rule.id) %>%
  summarise(freq = n())

qplot(data = e.agg,
      facets = . ~ rule.id,
      x = num.pos,
      y = num.neg,
      size = freq) +
  geom_abline() + 
  scale_x_continuous(name = '# positive examples', breaks = c(0, 3, 6), limits = c(0, 7)) +
  scale_y_continuous(name = '# negative examples', breaks = c(0, 3, 6), limits = c(0, 7))
```

things are somewhat balanced -- people tend to give some negative examples.

### q: do people give more positive examples than negative?

simple check -- paired t-test between number of positive and number of negative examples for each trial X user.

```{r}
e.agg = responses %>% group_by(worker.id, rule.id) %>%
  summarise(num.pos = sum(polarity == "positive"),
            num.neg = sum(polarity == "negative"))

with(e.agg, t.test(num.pos, num.neg, paired = TRUE))
```

no, doesn't look like it.


## how related are the examples in edit distance?

```{r}
# nb: cluster label numbers do not correspond to chronological order
cluster.examples = function(strings, distance.threshold = 2) {
  distance.matrix = adist(strings)
  
  # for each string, figure out which other strings it's similar to
  # (i.e., has edit distance less than the threshold)
  similarities = Map(1:nrow(distance.matrix),
                     f = function(row.num) {
                       r = distance.matrix[row.num,]
                       which(r <= distance.threshold)
                     })
  
  dirty.clusters = list()
  # print(similarities)
  
  overlap = function(a,b) {
    length(intersect(a,b)) > 0
  }
  
  Map(1:length(strings),
      f = function(i) {
        # j is the index of the previously created cluster that can contain this string
        j = Position(x = dirty.clusters,
                     f = function(dcluster) { i %in% dcluster })
        
        if (is.na(j)) {
          dirty.clusters[[length(dirty.clusters) + 1]] <<- similarities[[i]]
        } else {
          dirty.clusters[[j]] <<- union(dirty.clusters[[j]], similarities[[i]])
        }
      })
  
  ## clean up clusters
  clusters = list()
  for(i in 1:length(dirty.clusters)) {
    x = dirty.clusters[[i]]
    overlaps = unique(c(x, unlist(Filter(clusters, f = function(y) { overlap(x,y) }))))
    nonoverlaps = Filter(clusters, f = function(y) { !overlap(x,y) })
    clusters <- c(list(overlaps), nonoverlaps)
    #print(clusters)
    #browser()
  }

  
  # # return a list of clusters (each cluster is a vector containing strings that are clustered together)
  # Map(clusters, f = function(indices) { strings[indices] })

  ### WIP ###
  # return a data frame with two columns: string and cluster number
  x = do.call(rbind,
          Map(clusters,
              1:length(clusters),
              f = function(indices, cluster.label) {
                data.frame(string = strings[indices],
                           cluster.label = cluster.label)
              }
          ))

  x
}

# # testing
#strings = c("aa","bb","bbbb", "bbbbbb") # should be 1 cluster
#strings = c("aa","ab","xxx","xxyy") # should be 2 clusters
strings = c("11394", "95834", "13094", "52349", "1234b", "j1344", "123b4") # should be 2 clusters, 7 strings
#strings = c("12345", "12a34", "72384", "7238l", "sdfgf", "75348", "98765")
#strings = c("01234", "012a4", "62804", "628041", "y6280", "0123", "280", "a280b")
#strings = c('aaa','aa','aaab','baaaab','bbaaabb')
#strings = c("94301", "40510", "33333", "r2349", "asdfa", "3621", "834920")
cluster.examples(strings)
```

mean number of clusters for an example sequence:

```{r}
responses.clustered = responses %>%
  group_by(worker.id, rule.id) %>%
  mutate(cluster.label = cluster.examples(string)$cluster.label)

e.agg = responses.clustered %>%
  group_by(worker.id, rule.id) %>%
  summarise(num.clusters = max(cluster.label)) %>%
  group_by(worker.id) %>%
  summarise(mean_num.clusters = mean(num.clusters))

mean.num.clusters = mean(e.agg$mean_num.clusters)

summary(e.agg$mean_num.clusters)
```

TODO: do there tend to be more negative examples within a cluster? (i think people might come up with one example and then demonstrate various ways it can be perturbed to be a non-example)

TODO: do examples within a cluster tend to be nearby in the sequence of examples the user gave?

comparison to permutation test: sample random participants by sampling from pool of all participants' responses (note that this is sampling *without* replacement, as people wouldn't give the same example twice)
- runtime note: takes around 770 seconds for 5k bootstrap samples. it's a little slow because my clustering function is not vectorized

```{r}
sample.bootstrap.subject = function(worker.id, rule.id) {
  # get examples given by all participants for this rule
  ## written in non-dplyr syntax because i think it might be faster?
  pool = responses[responses$rule.id == rule.id,]
  pool.pos = pool[pool$polarity == 'positive',]$string
  pool.neg = pool[pool$polarity == 'negative',]$string
  
  # get this worker's examples
  this = pool[pool$worker.id == worker.id,]
  
  num.pos = sum(this$polarity == 'positive')
  num.neg = sum(this$polarity == 'negative')
  
  syn.pos = sample(x = pool.pos, size = num.pos, replace = FALSE)
  syn.neg = sample(x = pool.neg, size = num.neg, replace = FALSE)
  
  c(num.clusters = max(cluster.examples(c(syn.pos, syn.neg))$cluster.label))
}

workers.and.rules = responses.clustered[,c('worker.id', 'rule.id')]

clusters.bootstrap = function() {
  num.clusters = apply(workers.and.rules,
                       1,
                       function(e) { 
                         sample.bootstrap.subject(e['worker.id'], e['rule.id'])
                       })
  
  mean(num.clusters)
}

time = system.time(bootstrap.samples <- replicate(10, clusters.bootstrap()))

writeLines(paste0("elapsed seconds: ", round(unname(time['elapsed']), 1)))

writeLines(paste0('95% ci for bootstrap: ', paste0(quantile(bootstrap.samples, c(0.025, 0.0975)), collapse = " - ")))

# one-tailed test: how many bootstrap samples have a mean
# number of clusters less than the observed sample?
sum(bootstrap.samples < mean.num.clusters) / length(bootstrap.samples)
```

bootstrapping takes ~2 seconds per sample

TODO: the ways i've done both permutation tests are, i think, reasonable, but there are also reasonable alternatives. talk through my choices with mike, then write down rationale.

## how many mistakes do people make? (e.g., positive examples that don't actually match or negative examples that do match)


by stimulus:

```{r}
responses %>%
  group_by(rule.id) %>%
  summarise(error.rate = sum(!correct) / n())
```

inspecting errors:

```{r}
responses %>% filter(!correct) %>% select(rule.id, worker.id, string, polarity, match, correct) %>% arrange(rule.id)
```

TODO


by person:
```{r}
e = responses %>%
  group_by(worker.id) %>%
  summarise(error.rate = sum(!correct) / n()) %>% 
  arrange(desc(error.rate))

qplot(data = e,
      x = error.rate,
      geom = 'histogram')
```

there's quite a heavy tail of people that make errors. what's up with the outliers?

```{r}
e %>% filter(error.rate > 0.4) %>% merge(responses) %>%
  select(worker.id, rule.id, example.num, polarity, string)
```

one lazy worker and some people that didn't understand the instructions.

## how long are the examples that people give?

by stimulus:

```{r, fig.width = 11, fig.height = 3}
qplot(data = responses %>% filter(nchar(string) < 25),
      facets = . ~ rule.id,
      x = nchar(string),
      binwidth = 1,
      color = I('white'))
```

by person:

```{r}
qplot(data = responses,
      x = worker.id,
      y = nchar(string), alpha = I(0.5)) + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

## do people give examples in particular orders? e.g., shorter ones first or positive ones first?

### length

un-zscored:
```{r}
e = responses %>%
  transform(len = nchar(string)) %>%
  group_by(example.num) %>%
  summarise(mean.len = mean(len),
            cl.len = generic.ci(len)['ci.l'],
            cu.len = generic.ci(len)['ci.u']) %>%
  ungroup

qplot(data = e,
      x = example.num,
      y = mean.len,
      ymin = cl.len,
      ymax = cu.len,
      geom = c('pointrange','line'))
```

note: confidence intervals for last two points are actually huge (very few unique data values, e.g., 1)

un-z-scored, broken down by rule:

```{r}
e = responses %>%
  transform(len = nchar(string)) %>%
  group_by(example.num, rule.id) %>%
  summarise(mean.len = mean(len),
            cl.len = generic.ci(len)['ci.l'],
            cu.len = generic.ci(len)['ci.u']) %>%
  ungroup

qplot(data = e,
      facets = . ~ rule.id,
      x = example.num,
      y = mean.len,
      ymin = cl.len,
      ymax = cu.len,
      geom = c('pointrange','line'))
```


z-scoring length per subject per rule:
```{r}
z.score <- function(xs) {
  centered = xs - mean(xs)
  if (length(xs) == 1) {
    centered
  } else {
    # NB: deliberately doesn't catch the case where all xs are the same
    # because i filter for this later on
    centered / sd(xs)
  }
}

e = responses %>%
  transform(len = nchar(string)) %>%
  group_by(worker.id, rule.id) %>%
  mutate(z.len = z.score(len)) %>%
  mutate(z.len = ifelse(is.nan(z.len), 0, z.len)) %>%
  group_by(example.num) %>%
  summarise(mean.z.len = mean(z.len),
            cl.len = generic.ci(z.len)['ci.l'],
            cu.len = generic.ci(z.len)['ci.u']) %>%
  ungroup

qplot(data = e,
      x = example.num,
      y = mean.z.len,
      ymin = cl.len,
      ymax = cu.len,
      geom = c('pointrange','line'))
```

doesn't appear to be any sequencing over all the participants; are there particular cases where this happens? (TODO)


break out previous plot by rule.id:

```{r, fig.width = 11, fig.height = 3}
z.score <- function(xs) {
  centered = xs - mean(xs)
  if (length(xs) == 1) {
    centered
  } else {
    # NB: deliberately doesn't catch the case where all xs are the same
    # because i filter for this later on
    centered / sd(xs)
  }
}

e = responses %>%
  transform(len = nchar(string)) %>%
  group_by(worker.id, rule.id) %>%
  mutate(z.len = z.score(len)) %>%
  mutate(z.len = ifelse(is.nan(z.len), 0, z.len)) %>%
  group_by(example.num, rule.id) %>%
  summarise(mean.z.len = mean(z.len),
            cl.len = generic.ci(z.len)['ci.l'],
            cu.len = generic.ci(z.len)['ci.u']) %>%
  ungroup

qplot(data = e,
      facets = . ~ rule.id,
      x = example.num,
      y = mean.z.len,
      ymin = cl.len,
      ymax = cu.len,
      geom = c('pointrange','line'))
```


for each rule, plot each person's length curve individually:

```{r, fig.width = 8, fig.height = 4, dev="svg"}
e = responses %>%
  transform(len = nchar(string)) %>%
  group_by(worker.id, rule.id) %>%
  mutate(z.len = z.score(len), num.examples = max(example.num)) %>%
  mutate(z.len = ifelse(is.nan(z.len), 0, z.len)) %>%
  filter(num.examples > 1)

qplot(data = e,
      facets = rule.id ~ num.examples,
      x = example.num,
      y = z.len,
      geom = 'line',
      group = worker.id) +
  geom_point(mapping = aes(color = polarity)) +
  scale_color_brewer(palette = "Set1")
```

very busy graph. just looking at polarity:
```{r}
e = responses %>%
  transform(len = nchar(string)) %>%
  group_by(worker.id, rule.id) %>%
  mutate(z.len = z.score(len), num.examples = max(example.num)) %>%
  mutate(z.len = ifelse(is.nan(z.len), 0, z.len))

e = ddply(e, .(rule.id), function(ee) {
  # add dummy indices that are used to layout example sequences vertically
  ee = ee %>%
    arrange(num.examples) %>%
    transform(sort.order = 1:nrow(ee)) # merging will change the order so keep a way of restoring it
  dummy.df = data.frame(worker.id = unique(ee$worker.id))
  dummy.df$dummy.id = 1:nrow(dummy.df)
  merge(ee, dummy.df) %>% arrange(sort.order)
})

qplot(data = e,
      facets = . ~ rule.id,
      x = example.num,
      y = dummy.id,
      fill = polarity,
      color = I('white'),
      geom = 'tile') +
  scale_fill_brewer(palette = "Set1")
```




- 2-examples are balanced
- we see few entirely positive sequences
- possible pattern: all positive followed by all negative


### polarity

```{r}
e = responses %>%
        group_by(example.num) %>%
        summarise(frac.pos = sum(polarity == 'positive') / n(),
                  ci.l = generic.ci(polarity == 'positive')['ci.l'],
                  ci.u = generic.ci(polarity == 'positive')['ci.u'])

qplot(data = e,
      x = example.num,
      y = frac.pos,
      ymin = ci.l,
      ymax = ci.u,
      geom = c('pointrange','line'))
```

interesting -- first example tends to be positive.
also interesting: subsequent examples are roughly a coin flip between positive and negative. so maybe this is where the significant 0.45 more positive examples than negative comes from -- just the first one? (no, see above)

#### within a cluster, does the first example tend to be positive?

```{r}
e = responses.clustered %>%
  group_by(worker.id, rule.id, cluster.label) %>%
  summarise(first.cluster.example.polarity = polarity[1]) %>%
  ungroup() %>%
  select(first.cluster.example.polarity) %>%
  table

print(e)

prop.test(x = e['positive'], n = sum(e))
```

no. looks like it's just the very first example that tends to be positive

## misc

did 90210 show up as a zip code much?
```{r}
responses %>% filter(rule.id == 'zip-code', string == '90210')
```

no

## looking at raw examples

## 3a

## delimiters

### only one person nested the brackets (either positively or negatively)

```{r}
responses %>% filter(grepl("\\[\\[", string)) %>% select(worker.id, trial.num, example.num, polarity, string)
```


## zip-code

### negative examples are somewhat purely numeric (less than d02 though)

```{r}
e = responses %>%
  filter(rule.id == 'zip-code', polarity == 'negative') %>%
  {example.matches(.$string, "[0123456789]+")}

print(table(e))

prop.test(x = sum(e == TRUE), n = length(e))
```

in d02, i framed this rule in terms of actual zip codes and the negative examples that people gave were, for the most part, entirely numeric.
here, they tend to give more examples that are not entirely numeric.

