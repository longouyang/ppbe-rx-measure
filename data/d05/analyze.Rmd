---
title: "d05a analysis"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries}
library(MASS)
library(plyr)
library(tidyverse)
library(lubridate)
library(memoise)
```

```{r utilities}
generic.ci_ <- function(x, n = 5000, seed = 1) {
  set.seed(seed)
  lenx = length(x)
  
  structure(
    quantile(
      replicate(n, mean(x[sample.int(lenx, replace = TRUE)])),
      c(0.025, 0.975)),
    names=c("ci.l","ci.u"))
}

generic.ci <- memoise(generic.ci_)
```

# read in data

```{r}
results.dir = "production-results/"
assignments = read_csv(paste0(results.dir, "assignments.csv")) %>%
  mutate(accept.time = ymd_hms(accept.time),
         submit.time = ymd_hms(submit.time),
         duration = difftime(submit.time, accept.time, units = "mins"))
responses = read_csv(paste0(results.dir, "responses.csv"),
                     col_types = cols(string = col_character()))

## arrange assignments in order of time
assignments = assignments %>% arrange(accept.time)
```


```{r compute-example-correctness}
regexes = c('3a' = 'aaa+',
            'zip-code' = '[0123456789]{5}',
            'suffix-s' = '.*s\\>',
            'delimiters' = "\\[.*\\]")

example.matches = function(example, rx) {
  res = regexpr(pattern = rx, text = example)
  # make sure we match and that the *entire* string is what matches, not a substring
  res > 0 & attr(res, "match.length") == nchar(example)
}
# example.correct(example = 'aaa', rx = 'aaa+')
# example.correct(example = 'baaa', rx = 'aaa+')
# example.correct(example = 'aaaa', rx = 'aaa+')

responses = responses %>%
  mutate(rx = regexes[rule.id])

responses_match = apply(responses[,c('string','rx')],
      1,
      function(e) { example.matches(example = e['string'], rx = e['rx']) })

responses = responses %>%
  mutate(match = responses_match,
         correct = !xor(polarity == 'positive', match)) %>%
  select(-rx, -rule.desc) # hide these cause they're verbose

# # testing
# View(responses %>% select(rule.id, polarity, string, correct, match) %>% arrange(rule.id, polarity))
```


# auxiliary

## how long does the task take?

```{r}
qplot(data = assignments,
      x = as.numeric(duration),
      binwidth = 1,
      color = I('white')) + 
  xlab("duration (minutes)")
```


## what did people think was a fair payment?

```{r}
fair.pay = gsub("\\$","",assignments$fair_pay) %>% 
  as.numeric %>% na.omit
fair.pay = fair.pay[fair.pay < 6]
qplot(x = fair.pay,
      binwidth = 0.1,
      color = I('white')
      )
```

## how old are people?

```{r}
qplot(data = assignments,
      x = age,
      binwidth = 5)
```

they all tend to be older

## what gender are they?

```{r}
table(tolower(substr(assignments$gender, start = 1, stop = 1)))
```

## what is their programming / regex experience?

```{r}
assignments %>% select(worker.id, programming.experience) %>% arrange(desc(nchar(programming.experience)))
```
there's maybe 16 people with some sort of programming experience.

```{r}
assignments %>% select(worker.id, regex.experience) %>% arrange(desc(nchar(regex.experience)))
```

### do the people with regex experience give interesting examples?

```{r}
regex.knowers = c("ebda6ed", "d2f7661", "c8cecf0", "a33a11b", "9eabb06", "1dc006e", "ec8b199", "e12e476")
responses %>% filter(worker.id %in% regex.knowers) %>% select(worker.id, rule.id, example.num, polarity, string)
```



TODO: analyze

## any bugs?

```{r}
assignments %>% select(bugs, worker.id) %>% arrange(desc(nchar(bugs)))
```

largely smooth

## how much did they enjoy the task?

```{r}
assignments %>% select(enjoy) %>% arrange(desc(nchar(enjoy)))
```

It was decent

# research

## how many examples do people give?

```{r, fig.width = 11, fig.height = 3}
e.agg = responses %>% group_by(worker.id, rule.id) %>%
  summarise(num.examples = n()) %>%
  group_by(rule.id, num.examples) %>%
  summarise(freq = n())

xmin = 1 #min(e.agg$num.examples)
xmax = max(e.agg$num.examples)

e.agg$num.examples.fct = factor(e.agg$num.examples, levels = as.character(xmin:xmax))

ggplot(data = e.agg) +
  facet_grid(. ~ rule.id) +
  geom_bar(mapping = aes(x = num.examples.fct, y = freq), stat = 'identity') +
  scale_x_discrete(breaks = as.character(xmin:xmax), drop = FALSE, name = 'number of examples')
```

## q: do 2-examples tend to be *balanced*? i.e., one positive and one negative?

```{r}
e.agg = responses %>%
  group_by(worker.id, rule.id) %>%
  mutate(num.examples = length(string)) %>%
  filter(num.examples == 2) %>%
  group_by(worker.id, rule.id) %>%
  summarise(num.pos = sum(polarity == 'positive'),
            num.neg = sum(polarity == 'negative'))

print(table(e.agg$num.pos, e.agg$num.neg))

# proportion test on the frequency of balanced 2-examples
prop.test(x = sum(e.agg$num.pos == 1), nrow(e.agg))
```

yes, though not significantly (though i don't have a whole lot of data)

### for balanced 2-examples, what is the mean edit distance?

```{r}
e.agg = responses %>%
  group_by(worker.id, rule.id) %>%
  mutate(num.examples = length(string)) %>%
  filter(num.examples == 2, sum(polarity == 'positive') == 1) %>%
  summarise(edit.distance = adist(string)[1,2])

mean.balanced.pair.edit.distance = mean(e.agg$edit.distance)

qplot(data = e.agg,
      x = edit.distance,
      color = I('white'),
      binwidth = 1) + scale_x_continuous(breaks = with(e.agg, min(edit.distance):max(edit.distance))) +
  geom_vline(xintercept = mean.balanced.pair.edit.distance, color = I('red'))
```

mean is red line -- 4.41.

are these examples are closer than you'd expect by chance? (permutation test)

```{r}
e.agg = responses %>%
  group_by(worker.id, rule.id) %>%
  mutate(num.examples = length(string)) %>%
  filter(num.examples == 2, sum(polarity == 'positive') == 1)

workers.and.rules = e.agg[,c('worker.id', 'rule.id')]

balanced.example.pair.edit.distance.bootstrap = function(pool) {
  # sample a permuted dataset:
  # for each rule, shuffle all the examples and then pair them off
  # then for each pair, compute edit distance
  
  syn.df = ddply(pool,
        .(rule.id), function(e) {
          pool.pos = e[e$polarity == 'positive',]$string
          pool.neg = e[e$polarity == 'negative',]$string
          
          syn.pos = sample(pool.pos)
          syn.neg = sample(pool.neg)
          
          syn = rbind(syn.pos, syn.neg)
          
          data.frame(distance = apply(X = syn, MARGIN = 2, F = function(pair) { adist(pair)[1,2] }))
        })
  
  mean(syn.df$dist)
}

time = system.time(bootstrap.samples <- replicate(5000, balanced.example.pair.edit.distance.bootstrap(e.agg)))

writeLines(paste0("elapsed seconds: ", round(unname(time['elapsed']), 1)))

writeLines(paste0('95% ci for bootstrap: ', paste0(quantile(bootstrap.samples, c(0.025, 0.0975)), collapse = " - ")))

# one-tailed test: how many bootstrap samples have a mean
# number of clusters less than the observed sample?
sum(bootstrap.samples < mean.balanced.pair.edit.distance) / length(bootstrap.samples)
```

yes, this fewer than you'd expect by chance.

## how many positive examples versus negative examples?

```{r, fig.width = 11, fig.height = 3}
e.agg = responses %>% group_by(worker.id, rule.id) %>%
  summarise(num.pos = sum(polarity == "positive"),
            num.neg = sum(polarity == "negative")) %>%
  ungroup() %>%
  group_by(num.pos, num.neg, rule.id) %>%
  summarise(freq = n())

qplot(data = e.agg,
      facets = . ~ rule.id,
      x = num.pos,
      y = num.neg,
      size = freq) +
  geom_abline() + 
  scale_x_continuous(name = '# positive examples', breaks = c(0, 3, 6), limits = c(0, 7)) +
  scale_y_continuous(name = '# negative examples', breaks = c(0, 3, 6), limits = c(0, 7))
```

things are somewhat balanced -- people tend to give some negative examples.

### q: do people give more positive examples than negative?

simple check -- paired t-test between number of positive and number of negative examples for each trial X user.

```{r}
e.agg = responses %>% group_by(worker.id, rule.id) %>%
  summarise(num.pos = sum(polarity == "positive"),
            num.neg = sum(polarity == "negative"))

with(e.agg, t.test(num.pos, num.neg, paired = TRUE))
```

no, doesn't look like it.


## how related are the examples in edit distance?

```{r}
# nb: cluster label numbers do not correspond to chronological order
cluster.examples = function(strings, distance.threshold = 2) {
  distance.matrix = adist(strings)
  
  # for each string, figure out which other strings it's similar to
  # (i.e., has edit distance less than the threshold)
  similarities = Map(1:nrow(distance.matrix),
                     f = function(row.num) {
                       r = distance.matrix[row.num,]
                       which(r <= distance.threshold)
                     })
  
  dirty.clusters = list()
  # print(similarities)
  
  overlap = function(a,b) {
    length(intersect(a,b)) > 0
  }
  
  Map(1:length(strings),
      f = function(i) {
        # j is the index of the previously created cluster that can contain this string
        j = Position(x = dirty.clusters,
                     f = function(dcluster) { i %in% dcluster })
        
        if (is.na(j)) {
          dirty.clusters[[length(dirty.clusters) + 1]] <<- similarities[[i]]
        } else {
          dirty.clusters[[j]] <<- union(dirty.clusters[[j]], similarities[[i]])
        }
      })
  
  ## clean up clusters
  clusters = list()
  for(i in 1:length(dirty.clusters)) {
    x = dirty.clusters[[i]]
    overlaps = unique(c(x, unlist(Filter(clusters, f = function(y) { overlap(x,y) }))))
    nonoverlaps = Filter(clusters, f = function(y) { !overlap(x,y) })
    clusters <- c(list(overlaps), nonoverlaps)
    #print(clusters)
    #browser()
  }

  
  # # return a list of clusters (each cluster is a vector containing strings that are clustered together)
  # Map(clusters, f = function(indices) { strings[indices] })

  ### WIP ###
  # return a data frame with two columns: string and cluster number
  x = do.call(rbind,
          Map(clusters,
              1:length(clusters),
              f = function(indices, cluster.label) {
                data.frame(string = strings[indices],
                           cluster.label = cluster.label)
              }
          ))

  x
}

# # testing
#strings = c("aa","bb","bbbb", "bbbbbb") # should be 1 cluster
#strings = c("aa","ab","xxx","xxyy") # should be 2 clusters
strings = c("11394", "95834", "13094", "52349", "1234b", "j1344", "123b4") # should be 2 clusters, 7 strings
#strings = c("12345", "12a34", "72384", "7238l", "sdfgf", "75348", "98765")
#strings = c("01234", "012a4", "62804", "628041", "y6280", "0123", "280", "a280b")
#strings = c('aaa','aa','aaab','baaaab','bbaaabb')
#strings = c("94301", "40510", "33333", "r2349", "asdfa", "3621", "834920")
cluster.examples(strings)
```

mean number of clusters for an example sequence:

```{r}
responses.clustered = responses %>%
  group_by(worker.id, rule.id) %>%
  mutate(cluster.label = cluster.examples(string)$cluster.label)

e.agg = responses.clustered %>%
  group_by(worker.id, rule.id) %>%
  summarise(num.clusters = max(cluster.label)) %>%
  group_by(worker.id) %>%
  summarise(mean_num.clusters = mean(num.clusters))

mean.num.clusters = mean(e.agg$mean_num.clusters)

summary(e.agg$mean_num.clusters)
```

TODO: do there tend to be more negative examples within a cluster? (i think people might come up with one example and then demonstrate various ways it can be perturbed to be a non-example)

TODO: do examples within a cluster tend to be nearby in the sequence of examples the user gave?

comparison to permutation test: sample random participants by sampling from pool of all participants' responses (note that this is sampling *without* replacement, as people wouldn't give the same example twice)
- runtime note: takes around 770 seconds for 5k bootstrap samples. it's a little slow because my clustering function is not vectorized

```{r}
sample.bootstrap.subject = function(worker.id, rule.id) {
  # get examples given by all participants for this rule
  ## written in non-dplyr syntax because i think it might be faster?
  pool = responses[responses$rule.id == rule.id,]
  pool.pos = pool[pool$polarity == 'positive',]$string
  pool.neg = pool[pool$polarity == 'negative',]$string
  
  # get this worker's examples
  this = pool[pool$worker.id == worker.id,]
  
  num.pos = sum(this$polarity == 'positive')
  num.neg = sum(this$polarity == 'negative')
  
  syn.pos = sample(x = pool.pos, size = num.pos, replace = FALSE)
  syn.neg = sample(x = pool.neg, size = num.neg, replace = FALSE)
  
  c(num.clusters = max(cluster.examples(c(syn.pos, syn.neg))$cluster.label))
}

workers.and.rules = responses.clustered[,c('worker.id', 'rule.id')]

clusters.bootstrap = function() {
  num.clusters = apply(workers.and.rules,
                       1,
                       function(e) { 
                         sample.bootstrap.subject(e['worker.id'], e['rule.id'])
                       })
  
  mean(num.clusters)
}

time = system.time(bootstrap.samples <- replicate(10, clusters.bootstrap()))

writeLines(paste0("elapsed seconds: ", round(unname(time['elapsed']), 1)))

writeLines(paste0('95% ci for bootstrap: ', paste0(quantile(bootstrap.samples, c(0.025, 0.0975)), collapse = " - ")))

# one-tailed test: how many bootstrap samples have a mean
# number of clusters less than the observed sample?
sum(bootstrap.samples < mean.num.clusters) / length(bootstrap.samples)
```

bootstrapping takes ~2 seconds per sample

TODO: the ways i've done both permutation tests are, i think, reasonable, but there are also reasonable alternatives. talk through my choices with mike, then write down rationale.

## how many mistakes do people make? (e.g., positive examples that don't actually match or negative examples that do match)


by stimulus:

```{r}
responses %>%
  group_by(rule.id) %>%
  summarise(error.rate = sum(!correct) / n())
```

inspecting errors:

```{r}
responses %>% filter(!correct) %>% select(rule.id, worker.id, string, polarity, match, correct) %>% arrange(rule.id)
```

TODO


by person:
```{r}
e = responses %>%
  group_by(worker.id) %>%
  summarise(error.rate = sum(!correct) / n()) %>% 
  arrange(desc(error.rate))

qplot(data = e,
      x = error.rate,
      geom = 'histogram')
```

there's quite a heavy tail of people that make errors. what's up with the outliers?

```{r}
e %>% filter(error.rate > 0.4) %>% merge(responses) %>%
  select(worker.id, rule.id, example.num, polarity, string)
```

one lazy worker and some people that didn't understand the instructions.

## how long are the examples that people give?

by stimulus:

```{r, fig.width = 11, fig.height = 3}
qplot(data = responses %>% filter(nchar(string) < 25),
      facets = . ~ rule.id,
      x = nchar(string),
      binwidth = 1,
      color = I('white'))
```

by person:

```{r}
qplot(data = responses,
      x = worker.id,
      y = nchar(string), alpha = I(0.5)) + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

## do people give examples in particular orders? e.g., shorter ones first or positive ones first?

### length

un-zscored:
```{r}
e = responses %>%
  transform(len = nchar(string)) %>%
  group_by(example.num) %>%
  summarise(mean.len = mean(len),
            cl.len = generic.ci(len)['ci.l'],
            cu.len = generic.ci(len)['ci.u']) %>%
  ungroup

qplot(data = e,
      x = example.num,
      y = mean.len,
      ymin = cl.len,
      ymax = cu.len,
      geom = c('pointrange','line'))
```

note: confidence intervals for last two points are actually huge (very few unique data values, e.g., 1)

un-z-scored, broken down by rule:

```{r}
e = responses %>%
  transform(len = nchar(string)) %>%
  group_by(example.num, rule.id) %>%
  summarise(mean.len = mean(len),
            cl.len = generic.ci(len)['ci.l'],
            cu.len = generic.ci(len)['ci.u']) %>%
  ungroup

qplot(data = e,
      facets = . ~ rule.id,
      x = example.num,
      y = mean.len,
      ymin = cl.len,
      ymax = cu.len,
      geom = c('pointrange','line'))
```


z-scoring length per subject per rule:
```{r}
z.score <- function(xs) {
  centered = xs - mean(xs)
  if (length(xs) == 1) {
    centered
  } else {
    # NB: deliberately doesn't catch the case where all xs are the same
    # because i filter for this later on
    centered / sd(xs)
  }
}

e = responses %>%
  transform(len = nchar(string)) %>%
  group_by(worker.id, rule.id) %>%
  mutate(z.len = z.score(len)) %>%
  mutate(z.len = ifelse(is.nan(z.len), 0, z.len)) %>%
  group_by(example.num) %>%
  summarise(mean.z.len = mean(z.len),
            cl.len = generic.ci(z.len)['ci.l'],
            cu.len = generic.ci(z.len)['ci.u']) %>%
  ungroup

qplot(data = e,
      x = example.num,
      y = mean.z.len,
      ymin = cl.len,
      ymax = cu.len,
      geom = c('pointrange','line'))
```

doesn't appear to be any sequencing over all the participants; are there particular cases where this happens? (TODO)


break out previous plot by rule.id:

```{r, fig.width = 11, fig.height = 3}
z.score <- function(xs) {
  centered = xs - mean(xs)
  if (length(xs) == 1) {
    centered
  } else {
    # NB: deliberately doesn't catch the case where all xs are the same
    # because i filter for this later on
    centered / sd(xs)
  }
}

e = responses %>%
  transform(len = nchar(string)) %>%
  group_by(worker.id, rule.id) %>%
  mutate(z.len = z.score(len)) %>%
  mutate(z.len = ifelse(is.nan(z.len), 0, z.len)) %>%
  group_by(example.num, rule.id) %>%
  summarise(mean.z.len = mean(z.len),
            cl.len = generic.ci(z.len)['ci.l'],
            cu.len = generic.ci(z.len)['ci.u']) %>%
  ungroup

qplot(data = e,
      facets = . ~ rule.id,
      x = example.num,
      y = mean.z.len,
      ymin = cl.len,
      ymax = cu.len,
      geom = c('pointrange','line'))
```


for each rule, plot each person's length curve individually:

```{r, fig.width = 8, fig.height = 4, dev="svg"}
e = responses %>%
  transform(len = nchar(string)) %>%
  group_by(worker.id, rule.id) %>%
  mutate(z.len = z.score(len), num.examples = max(example.num)) %>%
  mutate(z.len = ifelse(is.nan(z.len), 0, z.len)) %>%
  filter(num.examples > 1)

qplot(data = e,
      facets = rule.id ~ num.examples,
      x = example.num,
      y = z.len,
      geom = 'line',
      group = worker.id) +
  geom_point(mapping = aes(color = polarity)) +
  scale_color_brewer(palette = "Set1")
```

very busy graph. just looking at polarity:
```{r}
e = responses %>%
  transform(len = nchar(string)) %>%
  group_by(worker.id, rule.id) %>%
  mutate(z.len = z.score(len), num.examples = max(example.num)) %>%
  mutate(z.len = ifelse(is.nan(z.len), 0, z.len))

e = ddply(e, .(rule.id), function(ee) {
  # add dummy indices that are used to layout example sequences vertically
  ee = ee %>%
    arrange(num.examples) %>%
    transform(sort.order = 1:nrow(ee)) # merging will change the order so keep a way of restoring it
  dummy.df = data.frame(worker.id = unique(ee$worker.id))
  dummy.df$dummy.id = 1:nrow(dummy.df)
  merge(ee, dummy.df) %>% arrange(sort.order)
})

qplot(data = e,
      facets = . ~ rule.id,
      x = example.num,
      y = dummy.id,
      fill = polarity,
      color = I('white'),
      geom = 'tile') +
  scale_fill_brewer(palette = "Set1")
```




- 2-examples are balanced
- we see few entirely positive sequences
- possible pattern: all positive followed by all negative


### polarity

```{r}
e = responses %>%
        group_by(example.num) %>%
        summarise(frac.pos = sum(polarity == 'positive') / n(),
                  ci.l = generic.ci(polarity == 'positive')['ci.l'],
                  ci.u = generic.ci(polarity == 'positive')['ci.u'])

qplot(data = e,
      x = example.num,
      y = frac.pos,
      ymin = ci.l,
      ymax = ci.u,
      geom = c('pointrange','line'))
```

interesting -- first example tends to be positive.
also interesting: subsequent examples are roughly a coin flip between positive and negative. so maybe this is where the significant 0.45 more positive examples than negative comes from -- just the first one? (no, see above)

#### within a cluster, does the first example tend to be positive?

```{r}
e = responses.clustered %>%
  group_by(worker.id, rule.id, cluster.label) %>%
  summarise(first.cluster.example.polarity = polarity[1]) %>%
  ungroup() %>%
  select(first.cluster.example.polarity) %>%
  table

print(e)

prop.test(x = e['positive'], n = sum(e))
```

no. looks like it's just the very first example that tends to be positive


## looking at raw examples

## 3a

```{r}
responses %>% filter(rule.id == '3a') %>% select(-time, -match, -assignment.id) %>% arrange(correct) %>%
  transform(string.and.pol = paste0('"', string, '" ', c(positive = '+', negative = '-')[polarity], 
                                    ifelse(correct, "", "!")
                                    )) %>%
  group_by(worker.id) %>%
  summarise(exs = paste0(string.and.pol, collapse = ' | '))
```


## delimiters


```{r}
responses %>% filter(rule.id == 'delimiters') %>% select(-time, -match, -assignment.id) %>% arrange(correct) %>%
  transform(string.and.pol = paste0('"', string, '" ', c(positive = '+', negative = '-')[polarity], 
                                    ifelse(correct, "", "!")
                                    )) %>%
  group_by(worker.id) %>%
  summarise(exs = paste0(string.and.pol, collapse = ' ‖ '))
```


### did anyone nest the brackets? or show a special case?

```{r}
responses %>% filter(grepl("\\[\\[", string)) %>% select(worker.id, trial.num, example.num, polarity, string) %>% print
responses %>% filter(grepl("\\]\\]", string)) %>% select(worker.id, trial.num, example.num, polarity, string) %>% print
```

no one nested.

```{r}
responses %>% filter(grepl("\\[\\]", string)) %>% select(worker.id, trial.num, example.num, polarity, string) %>% print
```

several people showed the empty brackets special case.
also, dff3ecd and 9eabb06 did a good job -- they showed that the brackets must come at the beginning and end, they can't just be balanced.

## zip-code

```{r}
responses %>% filter(rule.id == 'zip-code') %>% select(-time, -match, -assignment.id) %>% arrange(correct) %>%
  transform(string.and.pol = paste0('"', string, '" ', c(positive = '+', negative = '-')[polarity], 
                                    ifelse(correct, "", "!")
                                    )) %>%
  group_by(worker.id) %>%
  summarise(exs = paste0(string.and.pol, collapse = ' ‖ '))
```



### negative examples are somewhat purely numeric

```{r}
e = responses %>%
  filter(rule.id == 'zip-code', polarity == 'negative') %>%
  {example.matches(.$string, "[0123456789]+")}

print(table(e))

prop.test(x = sum(e == TRUE), n = length(e))
```

fraction isn't significantly different from 0.5 but that's not the right baseline value.
also, this special case is kind of subsumed by the more general distance-to-language measure, so i should use that.

## suffix-s

```{r}
responses %>% filter(rule.id == 'suffix-s') %>% select(-time, -match, -assignment.id) %>% arrange(correct) %>%
  transform(string.and.pol = paste0('"', string, '" ', c(positive = '+', negative = '-')[polarity], 
                                    ifelse(correct, "", "!")
                                    )) %>%
  group_by(worker.id) %>%
  summarise(exs = paste0(string.and.pol, collapse = ' ‖ '))
```


interesting: d2f7661 gave lots of examples but the absence of related negative examples makes it seem less helpful to me:
their examples are: "eagles" + ‖ "pizzas" + ‖ "friends" + ‖ "asdfssss" + ‖ "3r280us" + ‖ "333333s" + ‖ "(*&(*^%%SDs" + ‖ "fasdfasdf" - ‖ "3333333" - ‖ "s" + ‖ "d" - ‖ "gwegw" - ‖ "eeeeee" -

by contrast, 032d129's examples are fewer but seem more helpful: "cats" + ‖ "dogs" + ‖ "dog" - ‖ "cat" -

