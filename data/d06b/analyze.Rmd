---
title: "d06b analysis"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries}
library(MASS)
library(plyr)
library(tidyverse)
library(lubridate)
library(memoise)
```

```{r utilities}
generic.ci_ <- function(x, n = 5000, seed = 1) {
  set.seed(seed)
  lenx = length(x)
  
  structure(
    quantile(
      replicate(n, mean(x[sample.int(lenx, replace = TRUE)])),
      c(0.025, 0.975)),
    names=c("ci.l","ci.u"))
}

generic.ci <- memoise(generic.ci_)
```

# read in data

```{r}
results.dir = "production-results/"
assignments = read_csv(paste0(results.dir, "assignments.csv")) %>%
  mutate(accept.time = ymd_hms(accept.time),
         submit.time = ymd_hms(submit.time),
         duration = difftime(submit.time, accept.time, units = "mins"))
gloss = read_csv(paste0(results.dir,"gloss.csv"))
gen = read_csv(paste0(results.dir, "generalization.csv"),
                     col_types = cols(string = col_character()))

## arrange assignments in order of time
assignments = assignments %>% arrange(accept.time)
```


```{r compute-example-correctness}
regexes = c('3a' = 'aaa+',
            'zip-code' = '[0123456789]{5}',
            'suffix-s' = '.*s\\>',
            'delimiters' = "\\[.*\\]")

example.matches = function(example, rx) {
  res = regexpr(pattern = rx, text = example)
  # make sure we match and that the *entire* string is what matches, not a substring
  res > 0 & attr(res, "match.length") == nchar(example)
}
# example.correct(example = 'aaa', rx = 'aaa+')
# example.correct(example = 'baaa', rx = 'aaa+')
# example.correct(example = 'aaaa', rx = 'aaa+')


# # testing
# View(responses %>% select(rule.id, polarity, string, correct, match) %>% arrange(rule.id, polarity))
```


# auxiliary

## how long does the task take?

```{r}
qplot(data = assignments,
      x = as.numeric(duration),
      binwidth = 1,
      color = I('white')) + 
  xlab("duration (minutes)")
```


## what did people think was a fair payment?

```{r}
fair.pay = assignments$fair_pay %>% as.numeric %>% na.omit
fair.pay = fair.pay[fair.pay < 5]
qplot(x = fair.pay,
      binwidth = 0.1,
      color = I('white')
      )
```

## how old are people?

```{r}
qplot(data = assignments,
      x = age,
      binwidth = 5)
```

they all tend to be older

## what gender are they?

```{r}
table(tolower(substr(assignments$gender, start = 1, stop = 1)))
```

## what is their programming / regex experience?

```{r}
assignments %>% select(programming.experience, regex.experience, worker.id, age, gender) %>% arrange(desc(nchar(programming.experience)))
```

## any bugs?

```{r}
assignments %>% select(bugs, worker.id) %>% arrange(desc(nchar(bugs)))
```

## how much did they enjoy the task?

```{r}
assignments %>% select(enjoy) %>% arrange(desc(nchar(enjoy)))
```

Better than average
some people were frustrated by the inductive nature of the task and the lack of feedback

# research


## how does generalization accuracy vary by rule.id and sequence?

```{r, fig.width = 8, fig.height = 10}
e = gen %>%
  group_by(rule.id, seq.id, worker.id) %>%
  summarise(score = mean(correct)) %>%
  group_by(rule.id, seq.id) %>%
  summarise(mean.score = mean(score),
            ci.l.score = generic.ci(score)['ci.l'],
            ci.u.score = generic.ci(score)['ci.u'],
            n = length(score)
            ) %>%
  transform(ci.l.score = ifelse(n == 1, 0, ci.l.score),
            ci.u.score = ifelse(n == 1, 1, ci.u.score)
            )
            

qplot(data = e,
      x = seq.id,
      y = mean.score,
      ymin = ci.l.score,
      ymax = ci.u.score,
      geom = 'pointrange'
      ) +
  #geom_text(mapping = aes(label = paste0('n = ',n), y = 0.05), size = 3) +
  facet_wrap(~ rule.id, scales = 'free', ncol = 1) + ylim(0, 1) +
  theme(axis.text.x = element_text(angle = -25, hjust = 0, size = 8))
```

focusing on just zip-code:

```{r}
qplot(data = e %>% filter(rule.id == 'zip-code'),
      x = seq.id,
      y = mean.score,
      ymin = ci.l.score,
      ymax = ci.u.score,
      geom = 'pointrange'
      ) +
  #geom_text(mapping = aes(label = paste0('n = ',n), y = 0.05), size = 3) +
  facet_grid(. ~ rule.id, scales = 'free') + ylim(0, 1) +
  theme(axis.text.x = element_text(angle = -25, hjust = 0, size = 5))
```

make cocolab talk plot for suffix-s:



```{r}
labels = c("cats [+] \n dogs [+] \n dog [-] \n cat [-]",
"kdfknein;kdsf-s [+] \n 4389hfp34r89hdudududs [+] \n 834p9h3qhfdududdu___78934h [-] \n h9hwp89h32phfhf [-]",
"lots [+] \n sneezes [+] \n breeze [-]",
"43353477s [+] \n 3kcn;zkespw [-] \n kdj../4s [+]",
"eagles [+]  pizzas [+] \n  friends [+] asdfssss [+] \n 3r280us [+]  333333s [+] \n (*&(*^%%SDs [+] \n fasdfasdf [-] 3333333 [-] \n s [+]  d [-] gwegw [-] \n eeeeee [-]")

qplot(data = e %>% filter(rule.id == 'suffix-s', seq.id %in% c("032d129", "13ab615", "402a4e5", "b2614f0", "d2f7661")),
      x = seq.id,
      y = mean.score,
      ymin = ci.l.score,
      ymax = ci.u.score,
      geom = 'pointrange'
      ) +
  #geom_text(mapping = aes(label = paste0('n = ',n), y = 0.05), size = 3) +
  facet_grid(. ~ rule.id, scales = 'free') + ylim(0.3, 1) +
  scale_x_discrete(labels = labels) +
  theme(axis.text.x = element_text(size = 12))

```



## do different example sequences yield different generalization patterns?


```{r}
score.by.stim = gen %>%
  group_by(rule.id, seq.id, string) %>%
  summarise(mean.score = mean(correct),
            ci.l.score = generic.ci(correct)['ci.l'],
            ci.u.score = generic.ci(correct)['ci.u'],
            n = length(correct)
            )
```

3a:

```{r}
x.order = score.by.stim %>%
  filter(rule.id == '3a') %>%
  group_by(string) %>%
  summarise(mean.score = mean(mean.score)) %>%
  arrange(mean.score) %>%
  {.$string}

e = score.by.stim %>% filter(rule.id == '3a')
e$order = match(e$string, x.order)

ggplot(data = e) +
  geom_point(mapping = aes(x = order, y = mean.score, group = seq.id, color = seq.id)) +
  geom_line(mapping = aes(x = order, y = mean.score, group = seq.id, color = seq.id)) +
  scale_x_continuous(breaks = 1:length(x.order), labels = x.order) +
  theme(axis.text.x = element_text(angle = -45, hjust = 0))
```



zip-code:
```{r}
x.order = score.by.stim %>%
  filter(rule.id == 'zip-code') %>%
  group_by(string) %>%
  summarise(mean.score = mean(mean.score)) %>%
  arrange(mean.score) %>%
  {.$string}

e = score.by.stim %>% filter(rule.id == 'zip-code')
e$order = match(e$string, x.order)

ggplot(data = e) +
  geom_point(mapping = aes(x = order, y = mean.score, group = seq.id, color = seq.id)) +
  geom_line(mapping = aes(x = order, y = mean.score, group = seq.id, color = seq.id)) +
  scale_x_continuous(breaks = 1:length(x.order), labels = x.order) +
  theme(axis.text.x = element_text(angle = -45, hjust = 0))
```

suffix-s:

```{r}
x.order = score.by.stim %>%
  filter(rule.id == 'suffix-s') %>%
  group_by(string) %>%
  summarise(mean.score = mean(mean.score)) %>%
  arrange(mean.score) %>%
  {.$string}

e = score.by.stim %>% filter(rule.id == 'suffix-s')
e$order = match(e$string, x.order)

ggplot(data = e) +
  geom_point(mapping = aes(x = order, y = mean.score, group = seq.id, color = seq.id)) +
  geom_line(mapping = aes(x = order, y = mean.score, group = seq.id, color = seq.id)) +
  scale_x_continuous(breaks = 1:length(x.order), labels = x.order) +
  theme(axis.text.x = element_text(angle = -45, hjust = 0))
```


delimiters:

```{r}
x.order = score.by.stim %>%
  filter(rule.id == 'delimiters') %>%
  group_by(string) %>%
  summarise(mean.score = mean(mean.score)) %>%
  arrange(mean.score) %>%
  {.$string}

e = score.by.stim %>% filter(rule.id == 'delimiters')
e$order = match(e$string, x.order)

ggplot(data = e) +
  geom_point(mapping = aes(x = order, y = mean.score, group = seq.id, color = seq.id)) +
  geom_line(mapping = aes(x = order, y = mean.score, group = seq.id, color = seq.id)) +
  scale_x_continuous(breaks = 1:length(x.order), labels = x.order) +
  theme(axis.text.x = element_text(angle = -45, hjust = 0))
```



## analyze all 32 zip-code seqs


```{r}
zall = read.csv('gloss-zip-all.csv')
```




```{r, fig.width = 8, fig.height = 10}
e = zall %>% group_by(seq.id) %>% summarise(correct = mean(regex.correct))

model.results.raw = read.csv('model-results-zip-code.csv')
model.results = model.results.raw %>%
  transform(L0_smooth = L0_smooth) %>%
  gather("model", "prob", 2:length(model.results.raw))


e = merge(e, model.results)# %>%
  #transform(seq.id = substring(seq.id, 0, 3))

cors = e %>% group_by(model) %>% summarise(r = cor(correct, prob))
facet_labeller = function(model.names) {
  model.names %>% merge(cors) %>%
    transform(model = paste0(model, " (r =", round(r,2), ")")) %>%
    select(model)
}

# add correlation to facet labels

p = ggplot(data = e,
      mapping = aes(y = correct)) +
  facet_wrap(~ model, ncol = 2, scales = 'free', labeller = facet_labeller) + 
  geom_point(mapping = aes(x = prob))
  #geom_text(mapping = aes(x = prob, label = seq.id), size = 2, position = 'jitter')

p
```


## analyze gloss correctness

```{r}
glosses.scored = read.csv('glosses-scored.csv') %>% rename(teacher.id = seq.id)
```

```{r, fig.width = 11, fig.height = 3}
e.agg = glosses.scored %>% group_by(rule.id, teacher.id) %>% summarise(correct = mean(regex.correct))

qplot(data = e.agg,
      facets = . ~ rule.id,
      x = correct,
      geom = 'histogram') + xlab("fraction of correct glosses for a sequence")
```

```{r}
glosses.scored %>% group_by(rule.id) %>% 
  summarise(correct = mean(regex.correct))
```

hmm, i was wrong in thinking that suffix-s and delimiters were the easiest (though delimiters does appear to be pretty easy)

## modelling

zip-code parameter sweep for L0:
```{r}
hum3a = glosses.scored %>% filter(rule.id == 'zip-code') %>% group_by(rule.id, teacher.id) %>% summarise(correct = mean(regex.correct), num.correct = sum(regex.correct), n = n())

mod3a = fromJSON('zip-L0.json') %>% merge(hum3a) %>% transform(outlierLP = round(outlierLP, 3))

mod3a = mod3a %>%
  transform(LL = dbinom(num.correct, size = n, prob = prob, log = TRUE))

model.fits = mod3a %>% group_by(outlierLP) %>% summarise(LL = sum(LL))
cors = mod3a %>% group_by(outlierLP) %>% summarise(r = cor(correct, prob))
facet_labeller = function(outlierLPs) {
  outlierLPs %>% merge(model.fits) %>%
    transform(outlierLP = paste0(outlierLP, " (r =", round(LL), ")")) %>%
    select(outlierLP)
}

qplot(data = mod3a %>% spread(model, prob),
      x = L0,
      y = correct) +
  facet_wrap( ~ outlierLP, labeller = facet_labeller) +
  xlim(0,1) + ylim(0,1) + geom_abline()
```

zip-code parameter sweep for L1:
```{r}
mod3a = fromJSON('zip-L1.json') %>% merge(hum3a) %>% transform(outlierLP = round(outlierLP, 3),
                                                              teacherAlpha = round(teacherAlpha, 3))

mod3a = mod3a %>%
  transform(LL = dbinom(num.correct, size = n, prob = prob, log = TRUE))

model.fits = mod3a %>% group_by(outlierLP, teacherAlpha) %>% summarise(LL = sum(LL))

qplot(data = model.fits %>% filter(is.finite(LL)),
      x = outlierLP,
      y = teacherAlpha,
      label = round(LL),
      geom = 'text',
      color = LL
      ) + theme_classic()
```

detailed view:
```{r}
qplot(data = mod3a %>% spread(model, prob),
      x = L1,
      y = correct) +
  facet_grid(teacherAlpha ~ outlierLP) +
  geom_text(data = model.fits, mapping = aes(x = 0.5, y = 0.95, label = round(LL)), color = 'deepskyblue') +
  xlim(0,1) + ylim(0,1) + geom_abline()
```



3a parameter sweep for L0:

```{r}
hum3a = glosses.scored %>% filter(rule.id == '3a') %>% group_by(rule.id, teacher.id) %>% summarise(correct = mean(regex.correct))

mod3a = fromJSON('3a-L0.json') %>% merge(hum3a) %>% transform(outlierLP = round(outlierLP, 3))

cors = mod3a %>% group_by(outlierLP) %>% summarise(r = cor(correct, prob))
facet_labeller = function(outlierLPs) {
  outlierLPs %>% merge(cors) %>%
    transform(outlierLP = paste0(outlierLP, " (r =", round(r,3), ")")) %>%
    select(outlierLP)
}

qplot(data = mod3a %>% spread(model, prob),
      x = L0,
      y = correct) +
  facet_wrap( ~ outlierLP, labeller = facet_labeller, nrow = 10) +
  xlim(0,1) + ylim(0,1) + geom_abline()
```

3a parameter sweep for L1:

```{r}
mod3a = fromJSON('3a-L1.json') %>% merge(hum3a) %>% transform(outlierLP = round(outlierLP, 3),
                                                              teacherAlpha = round(teacherAlpha, 3)
                                                              )

cors = mod3a %>% group_by(outlierLP, teacherAlpha) %>% summarise(r = cor(correct, prob))

qplot(data = mod3a %>% spread(model, prob),
      x = L1,
      y = correct) +
  facet_grid(teacherAlpha ~ outlierLP) +
  geom_text(data = cors, mapping = aes(x = 0.1, y = 0.95, label = round(r, 2))) +
  xlim(0,1) + ylim(0,1) + geom_abline()
```


